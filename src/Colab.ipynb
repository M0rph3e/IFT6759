{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U PyYAML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZUPooEgOHLa",
        "outputId": "e20a8f90-c555-492e-cadc-3bf2616acc64"
      },
      "id": "fZUPooEgOHLa",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5JF5V8SQ8nH",
        "outputId": "e6c35aa3-4d2f-45b3-d85e-038e2fc79e99"
      },
      "id": "z5JF5V8SQ8nH",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Link your assignment folder & install requirements\n",
        "#@markdown Enter the path to the assignment folder in your Google Drive\n",
        "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
        "# you can delete this cell which is specific to Google Colab. You may also\n",
        "# change the paths for data/logs in Arguments below.\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "folder = \"/content/gdrive/MyDrive/MILA/IFT6759/Project/src\" #@param {type:\"string\"}\n",
        "!ln -Ts \"$folder\" /content/src 2> /dev/null\n",
        "\n",
        "# Add the assignment folder to Python path\n",
        "if '/content/src' not in sys.path:\n",
        "  sys.path.insert(0, '/content/src')\n",
        "\n",
        "# Install requirements\n",
        "#!pip install -qr /content/assignment/requirements.txt\n",
        "\n",
        "# Check if CUDA is available\n",
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  warnings.warn('CUDA is not available.')"
      ],
      "metadata": {
        "id": "WQDryn3vQ9yZ"
      },
      "id": "WQDryn3vQ9yZ",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3740872e-d934-4408-8834-b7b25267d557",
      "metadata": {
        "id": "3740872e-d934-4408-8834-b7b25267d557"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "import numpy as np\n",
        "import pickle\n",
        "import logging\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "50332fc8-1852-4057-ae74-498a8a74f2b3",
      "metadata": {
        "id": "50332fc8-1852-4057-ae74-498a8a74f2b3"
      },
      "outputs": [],
      "source": [
        "with open('./src/Config/Config1.yaml') as f:\n",
        "    config = yaml.load(f, Loader=yaml.FullLoader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4c7742bd-30ec-4a75-92bf-49f9ab06ef5a",
      "metadata": {
        "id": "4c7742bd-30ec-4a75-92bf-49f9ab06ef5a"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "task = config[\"task\"]\n",
        "data_file = config[\"data\"]\n",
        "model_file = config[\"model\"]\n",
        "augment_file = config[\"augment\"]\n",
        "augment_strength = config[\"aug_strength\"]\n",
        "eval_file = config[\"eval\"]\n",
        "batch_size = config[\"batch_size\"]\n",
        "learn_rate = config[\"learning_rate\"]\n",
        "epoch = config[\"epoch\"]\n",
        "optimizer = config[\"optimizer\"]\n",
        "#momentum = config[\"momentum\"]\n",
        "weight_decay = config[\"weight_decay\"]\n",
        "seed = config[\"seed\"]\n",
        "epoch = config[\"epoch\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "eeb541e8-4db0-4107-ac7a-47c8a6ee7412",
      "metadata": {
        "id": "eeb541e8-4db0-4107-ac7a-47c8a6ee7412"
      },
      "outputs": [],
      "source": [
        "logging.info(f\"==========Dataset: {data_file}==========\")\n",
        "data_file_path = f\"Data.{data_file}\"\n",
        "_temp = __import__(name=data_file_path, fromlist=['Data_Load'])\n",
        "Data_Load = _temp.Data_Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3ef80f20-acff-4117-85de-6de6c415a932",
      "metadata": {
        "id": "3ef80f20-acff-4117-85de-6de6c415a932"
      },
      "outputs": [],
      "source": [
        "if augment_file == None:\n",
        "    print(\"No augmentation method selected\")\n",
        "else:\n",
        "    Aug = []\n",
        "    for i in range(len(augment_file)):\n",
        "        logging.info(f\"==========Augmentation Methods: {augment_file[i]}, with a strength value of {augment_strength[i]}==========\")\n",
        "        augment_file_path = f\"Augmentation.{augment_file[i]}\"\n",
        "        _temp = __import__(name=augment_file_path, fromlist=['Aug'])\n",
        "        Aug.append(_temp.Aug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8ee8877e-49e0-4628-b372-d28dd5e636ed",
      "metadata": {
        "id": "8ee8877e-49e0-4628-b372-d28dd5e636ed"
      },
      "outputs": [],
      "source": [
        "# Importing the model class\n",
        "logging.info(f\"==========Model Selected: {model_file}==========\")\n",
        "model_file_path = f\"Model.{model_file}\"\n",
        "_temp = __import__(name=model_file_path, fromlist=['ModelClass'])\n",
        "ModelClass = _temp.ModelClass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the evaluation methods\n",
        "logging.info(f\"==========Evaluation Method: {eval_file}==========\")\n",
        "eval_file_path = f\"Evaluation.{eval_file}\"\n",
        "_temp = __import__(name=eval_file_path, fromlist=['Eval'])\n",
        "Eval = _temp.Eval  "
      ],
      "metadata": {
        "id": "tqYfpYOYQ7_s"
      },
      "id": "tqYfpYOYQ7_s",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "44c72fb6-66ff-4156-a84d-4cf6b2e09fa2",
      "metadata": {
        "id": "44c72fb6-66ff-4156-a84d-4cf6b2e09fa2",
        "outputId": "c099b20d-2f94-400c-dbaa-cb4322273444",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "labelledloader, unlabelledloader, validloader, testloader = Data_Load(task = task, batch_size = batch_size, seed = seed)\n",
        "logging.info(\"Dataloader ready\")    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augment_count = np.multiply(len(labelledloader.dataset),augment_strength).astype(int)\n",
        "res_history = []\n",
        "idx_val = []\n",
        "idx_count = 0\n",
        "\n",
        "residual = labelledloader.batch_size\n",
        "for i in range(len(augment_count)):\n",
        "  current_residual = ( (augment_count[i] - (labelledloader.batch_size-residual))/labelledloader.batch_size - np.floor((augment_count[i] - (labelledloader.batch_size-residual))/labelledloader.batch_size) ) *labelledloader.batch_size\n",
        "  idx_count =  idx_count + (np.ceil((augment_count[i] - (labelledloader.batch_size-residual))/labelledloader.batch_size))\n",
        "  residual = current_residual\n",
        "  res_history.append(current_residual.astype(int))\n",
        "  idx_val.append(idx_count.astype(int)-1)\n"
      ],
      "metadata": {
        "id": "SRwSQKNPg-NJ"
      },
      "id": "SRwSQKNPg-NJ",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tot_accs, valid_tot_accs = [], []\n",
        "train_tot_losses, valid_tot_losses = [], []\n",
        "\n",
        "Model = ModelClass(optimizer=optimizer,lr=learn_rate,weight_decay=weight_decay)\n",
        "Model = Model.to(device=device)\n"
      ],
      "metadata": {
        "id": "1N1DcfWjPwqg"
      },
      "id": "1N1DcfWjPwqg",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ep in range(epoch):\n",
        "    \n",
        "    # logging.info(f\"==========Supervised Learning Epoch Number: {ep+1}/{epoch}==========\")\n",
        "    print(f\"==========Supervised Learning Epoch Number: {ep+1}/{epoch}==========\")\n",
        "    train_accs, valid_accs = [], []\n",
        "    train_losses, valid_losses = [], []\n",
        "    \n",
        "    count = 0\n",
        "\n",
        "    for idx, batch in enumerate(labelledloader):\n",
        "        data, target = batch\n",
        "        data = data.to(device=device)\n",
        "        labels = F.one_hot(target, num_classes = 10).float().to(device=device)\n",
        "\n",
        "        if augment_file != None:\n",
        "          if idx == idx_val[count]:\n",
        "            \n",
        "            if count+1 != len(Aug):\n",
        "              temp_Aug, temp_label = Aug[count](data[0:res_history[count]],labels[0:res_history[count]])\n",
        "              Aug_data = temp_Aug\n",
        "              Aug_labels = temp_label\n",
        "\n",
        "              temp_Aug, temp_label = Aug[count](data[res_history[count]:-1],labels[res_history[count]:-1])\n",
        "              Aug_data = torch.cat((Aug_data, temp_Aug), 0)\n",
        "              Aug_labels = torch.cat((Aug_labels, temp_label), 0)\n",
        "              \n",
        "              count = count+1\n",
        "            else:\n",
        "              temp_Aug, temp_label = Aug[count](data,labels)\n",
        "              Aug_data = temp_Aug\n",
        "              Aug_labels = temp_label\n",
        "          else:\n",
        "            temp_Aug, temp_label = Aug[count](data,labels)\n",
        "            Aug_data = temp_Aug\n",
        "            Aug_labels = temp_label\n",
        "        else:\n",
        "          Aug_data = torch.cat((data,data,data,data),0)\n",
        "          Aug_labels = torch.cat((labels,labels,labels,labels),0)\n",
        "\n",
        "        acc, loss = Model.train_sup_up(Aug_data,Aug_labels)\n",
        "        train_accs.append(acc)\n",
        "        train_losses.append(loss)\n",
        "    \n",
        "    train_tot_accs.append(sum(train_accs)/len(train_accs))\n",
        "    train_tot_losses.append(sum(train_losses)/len(train_losses))\n",
        "        \n",
        "    # logging.info(f\"==========Training Accuracy: {train_tot_accs[-1]:.3f} , Training Loss: {train_tot_losses[-1]:.3f}==========\")    \n",
        "    print(f\"==========Training Accuracy: {train_tot_accs[-1]:.3f} , Training Loss: {train_tot_losses[-1]:.3f}==========\")\n",
        "\n",
        "    for idx, batch in enumerate(validloader):\n",
        "        data, target = batch\n",
        "        data = data.to(device=device)\n",
        "        labels = F.one_hot(target, num_classes = 10).float().to(device=device)\n",
        "        acc, loss = Model.evaluation(data,labels)\n",
        "        valid_accs.append(acc)\n",
        "        valid_losses.append(loss)\n",
        "        \n",
        "    valid_tot_accs.append(sum(valid_accs)/len(valid_accs))\n",
        "    valid_tot_losses.append(sum(valid_losses)/len(valid_losses))\n",
        "    \n",
        "    # logging.info(f\"==========Validation Accuracy: {valid_tot_accs[-1]:.3f} , Validation Loss: {valid_tot_losses[-1]:.3f}==========\")    \n",
        "    print(f\"==========Validation Accuracy: {valid_tot_accs[-1]:.3f} , Validation Loss: {valid_tot_losses[-1]:.3f}==========\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0HhgqU-Pwwh",
        "outputId": "f641c1f2-0bdf-4cb5-d70f-8b0593cd544a"
      },
      "id": "F0HhgqU-Pwwh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========Supervised Learning Epoch Number: 1/50==========\n",
            "index 175, count is 0\n",
            "==========Training Accuracy: 0.308 , Training Loss: 1.929==========\n",
            "==========Validation Accuracy: 0.401 , Validation Loss: 2.080==========\n",
            "==========Supervised Learning Epoch Number: 2/50==========\n",
            "index 175, count is 0\n",
            "==========Training Accuracy: 0.471 , Training Loss: 1.447==========\n",
            "==========Validation Accuracy: 0.492 , Validation Loss: 2.043==========\n",
            "==========Supervised Learning Epoch Number: 3/50==========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(torch.stack(train_tot_accs).cpu().detach().numpy())\n",
        "\n",
        "plt.plot(torch.stack(valid_tot_accs).cpu().detach().numpy())\n"
      ],
      "metadata": {
        "id": "LuyzMt0MPwy2"
      },
      "id": "LuyzMt0MPwy2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.plot(torch.stack(train_tot_losses).cpu().detach().numpy())\n",
        "plt.plot(torch.stack(valid_tot_losses).cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "qQ7R6-1NPw1R"
      },
      "id": "qQ7R6-1NPw1R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accs = []\n",
        "test_losses = []\n",
        "\n",
        "for idx, batch in enumerate(testloader):\n",
        "    data, target = batch\n",
        "    data = data.to(device=device)\n",
        "    labels = F.one_hot(target, num_classes = 10).float().to(device=device)\n",
        "    acc, loss = Model.evaluation(data,labels)\n",
        "    test_accs.append(acc)\n",
        "    test_losses.append(loss)\n",
        "        \n",
        "test_tot_accs = (sum(train_accs)/len(train_accs))\n",
        "test_tot_losses = (sum(train_losses)/len(train_losses))\n",
        "            \n",
        "# logging.info(f\"==========Test Accuracy: {test_tot_accs:.3f} , Test Loss: {test_tot_losses:.3f}==========\") \n",
        "print(f\"==========Test Accuracy: {test_tot_accs:.3f} , Test Loss: {test_tot_losses:.3f}==========\")  "
      ],
      "metadata": {
        "id": "mm8YHG00Pw8C"
      },
      "id": "mm8YHG00Pw8C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kfHQcrGXJxRm"
      },
      "id": "kfHQcrGXJxRm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dPujnnpmJxUB"
      },
      "id": "dPujnnpmJxUB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle_path = f\"./Model/{args.config_file}.pickle\"\n",
        "pickle_path = f\"./src/Model/Example.pickle\"\n",
        "logging.info(\"Saving model to pickle file\")\n",
        "with open(pickle_path, \"wb\") as f:\n",
        "  pickle.dump(Model, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1sPKK8IaPw-L"
      },
      "id": "1sPKK8IaPw-L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PGXPl285PxAn"
      },
      "id": "PGXPl285PxAn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mK4Hh49CPxDF"
      },
      "id": "mK4Hh49CPxDF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LACw15sNPxFK"
      },
      "id": "LACw15sNPxFK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54aad525-bb5f-4d37-a3fd-ca14ff6553fe",
      "metadata": {
        "id": "54aad525-bb5f-4d37-a3fd-ca14ff6553fe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e58d84c3-a08f-4607-9f9c-a6c34a97c0aa",
      "metadata": {
        "id": "e58d84c3-a08f-4607-9f9c-a6c34a97c0aa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85077ec2-817d-4e92-9af5-ab7846b79381",
      "metadata": {
        "id": "85077ec2-817d-4e92-9af5-ab7846b79381"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "Colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}